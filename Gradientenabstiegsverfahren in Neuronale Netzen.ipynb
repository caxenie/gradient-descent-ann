{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Einsatz von Gradientenabstiegsverfahren in \n",
    "# Neuronalen Netzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inhalt\n",
    "\n",
    "- Grundlagen der Optimierung\n",
    "- Gradientenabstieg\n",
    "- Lernen als Optimierung in Neuronalen Netzen\n",
    "- Gradientenabstieg in Neuronalen Netzen\n",
    "- Nachteile des Gradientenabstiegs\n",
    "- Fazit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grundlagen der Optimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Grundlagen der Optimierung\n",
    "**Optimierungsalgorithmen** sind in der Regel **iterative Verfahren**. Ausgehend von einem gegebenen Punkt $ {x_0  \\color{red}{+}} $ erzeugen sie eine Folge ${x_k}$ von **Iterierten**, die zu einer Lösung ($\\color{red}{\\bullet}$) **konvergieren** [2].\n",
    "\n",
    "<center>![](./optimization.gif)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Grundlagen der Optimierung\n",
    "<center>![](./backprop-sketch/opt-types1-notext.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Grundlagen der Optimierung\n",
    "<center>![](./backprop-sketch/opt-types2-notext-single.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Grundlagen der Optimierung\n",
    "<center>![](./backprop-sketch/opt-types3-notext-single.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradientenabstieg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Gradientenabstieg\n",
    "<center>![](./backprop-sketch/gradient-descent-fig.png)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lernen als Optimierung in Neuronale Netzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Optimierungsalgorithmen helfen uns, eine **Zielfunktion zu minimieren (oder zu maximieren)**. Ein solche Zielfunktion ist in **neuronalen Netzen** eine **mathematische Funktion (E)**, die von den **internen lernbaren Parametern (W)** des Netzwerks abhängt [3].\n",
    "\n",
    "Diese **Parametern** werden bei der Berechnung der **erwarteten Werte (Y)** aus dem Satz von **Prädiktoren (X)** benutzt. \n",
    "\n",
    "**E** beschreibt die Differenz zwischen dem erwarteten Wert und dem **tatsächlichen Netzwerkausgangswert (O)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/basic-net.gif)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradientenabstieg in Neuronale Netzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Binäre Klassifikation mit neuronalen Netzen\n",
    "\n",
    "<center>![](./backprop-sketch/hausaufgabe.png)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/1.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/2.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/3.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/4.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/5.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/6.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/7.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/8.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/9.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/10.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/11.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/12.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/13.gif>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>![](./backprop-sketch/14.gif)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ausgabe des Programms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Erste Ausführung\n",
    "\n",
    "<center>![](./output-klass-96.png)</center>\n",
    "<center>![](./output-roc-96.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Zweite Ausführung\n",
    "<center>![](./output-klass-99.png)</center>\n",
    "<center>![](./output-roc-99.png)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Dritte Ausführung\n",
    "<center>![](./output-klass-100.png)</center>\n",
    "<center>![](./output-roc-100.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nachteile des Gradientenabstiegs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Nachteile des Gradientenabstiegs \n",
    "\n",
    "Abhängig von der Datenmenge machen wir einen **Kompromiss zwischen die Genauigkeit der Parameteraktualisierung und der Konvergenzgeschwindigkeit** [2, 4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Nachteile des Gradientenabstiegs\n",
    "<center>![](./gradient-problems.gif)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nachteile des Gradientenabstiegs\n",
    "\n",
    "Es wurden **verschiedene Methoden entwickelt**, um die Nechteile zum **beheben** [3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Gradient Descent | Nesterov Momentum |  Adaptive Moment Estimation (Adam) | \n",
    "|:---------:|:---------:|:---------:|\n",
    "| $ w_{t+1} = w_t - {\\alpha} {\\nabla E(w_t)}$   |  $ w_{t+1} = w_t - {\\alpha} {v_t} \\\\ { v_{t+1} = \\frac{\\gamma}{\\alpha} v_t  + {\\nabla E(w_t - \\gamma v_t)}} $  | $ w_{t+1} = w_t -{\\alpha} {\\frac{m_t}{\\sqrt{{v_t}}}}  \\\\ {m_{t+1} = f(\\nabla E(w_t) ) \\\\ v_{t+1} = f(\\nabla E(w_t)^2) }$| \n",
    "| $\\color{green}{+} $ einfache Aktualisierungsregel (z. B. Summe, Produkt)  | $\\color{green}{+}$ Beschleunigt in die jeweilige Steigungsrichtung und dämpft Schwingungen | $\\color{green}{+}$ speichert einen exponentiell abfallenden Durchschnitt vergangener Gradienten (glättendes Moment) mit adaptiver Lernrate für jeden parameter |\n",
    "| $\\color{red} {-}$ Konvergiert zum globalen Minimum für konvexe Fehleroberflächen und zu einem lokalen Minimum für nichtkonvexe Oberflächen | $\\color{red}{-}$ funktioniert nicht gut, wenn die Kostenfunktionen stark konvex sind | $\\color{red}{-}$ hat den niedrigsten Trainingsfehler, aber nicht den niedrigsten Validierungsfehler, und der Validierungsfehler ist größer als der Trainingsfehler (d. h. leichte Überanpassung) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nachteile des Gradientenabstiegs\n",
    "<center>![](./demo-anim.gif)</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nachteile des Gradientenabstiegs\n",
    "<center>![](./loss-anim.gif)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fazit\n",
    "\n",
    "- **Gradientenabstieg** ist die **typische Optimierungsmethode** in neuronalen Netzen.\n",
    "- **Lernen** in Neuronalen Netzen ist ein **iterativer Prozess**.\n",
    "- Bei der **Backpropagation** wird ein Gradientenabstieg verwendet, um zu einer **Lösung zu konvergieren** (d. h. die **Gewichte zu finden**), die die **Fehlerfunktion minimiert**.\n",
    "- **Gradientenabstieg** ist jedoch **problematisch** (Konvergenz, Präzision), aber es wurden viele **verbesserte Verfahren** entwickelt.\n",
    "- Das **Verständnis des Gradientenabstieg** bei der Diagnose der Backpropagation **ist für erfolgreiche Anwendungen erforderlich**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Literaturverzeichnis\n",
    "\n",
    "[1] https://google-developers.appspot.com/machine-learning/ (letzter Besuch, Dez 2019)\n",
    "\n",
    "[2] Boyd, S., & Vandenberghe, L. (2004). Convex optimization. Cambridge university press.\n",
    "\n",
    "[3] Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.\n",
    "\n",
    "[4] Ruder, S. (2016). An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Vorlesung Notebook herunterladen\n",
    "\n",
    "<img src=\"./qrcode.png\" style=\"width = 200, height=200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "center",
    "code_folding": [
     0,
     10,
     14,
     24,
     50,
     69,
     124,
     199
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f901dd75e10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN AUC=1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f901dd5c208>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Einfaches neuronales Netz zur binären Klassifikation\n",
    "import random\n",
    "import math\n",
    "import time as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def f(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "\n",
    "def df(x):\n",
    "    try:\n",
    "        return 1 / (math.cosh(x) ** 2)\n",
    "    except OverflowError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "class Network:\n",
    "    \n",
    "\n",
    "    def __init__(self, l_in, l_hid, l_out, rate=0.05):\n",
    "        self.num_layer_in = l_in\n",
    "        self.num_layer_hid = l_hid\n",
    "        self.num_layer_out = l_out\n",
    "\n",
    "        self.w1 = []\n",
    "        self.w2 = []\n",
    "\n",
    "        # init weights inputs -> hidden\n",
    "        for i in range(self.num_layer_in * self.num_layer_hid ):\n",
    "            self.w1.append(random.randrange(-10, 10) * 0.01)\n",
    "\n",
    "        # init weights hidden -> output\n",
    "        for i in range(self.num_layer_hid * self.num_layer_out):\n",
    "            self.w2.append(random.randrange(-10, 10) * 0.01)\n",
    "\n",
    "        # init weights bias -> hidden\n",
    "        for i in range(self.num_layer_hid):\n",
    "            self.w1.append(random.randrange(-10, 10) * 0.01)\n",
    "\n",
    "        # init weights bias -> output\n",
    "        for i in range(self.num_layer_out):\n",
    "            self.w2.append(random.randrange(-10, 10) * 0.01)\n",
    "\n",
    "        self.learning_rate = rate\n",
    "\n",
    "    def forward_propagation(self, data_in):\n",
    "        net_hid = 0\n",
    "        out_hid = []\n",
    "        net_out = 0\n",
    "\n",
    "        # Calculate net input and outputs for hidden layer\n",
    "        for i in range(self.num_layer_hid):\n",
    "            net_hid += float(data_in[0]) * self.w1[i]\n",
    "            net_hid += float(data_in[1]) * self.w1[i + self.num_layer_hid]\n",
    "            net_hid += self.w1[i + self.num_layer_in * self.num_layer_hid]\n",
    "            out_hid.append(f(net_hid))\n",
    "\n",
    "        # Calculate net input and output for output layer\n",
    "        for i in range(self.num_layer_hid):\n",
    "            net_out += out_hid[i] * self.w2[i]\n",
    "        net_out += self.w2[self.num_layer_hid * self.num_layer_out]\n",
    "\n",
    "        return f(net_out)\n",
    "\n",
    "    def train(self, train_data):\n",
    "        for data in train_data:\n",
    "            net_hid = []\n",
    "            out_hid = []\n",
    "            net_out = 0\n",
    "            out_out = 0\n",
    "\n",
    "            updates_w1 = []\n",
    "            updates_w2 = []\n",
    "\n",
    "            # Calculate net input and outputs for hidden layer\n",
    "            net = 0\n",
    "            for i in range(self.num_layer_hid):\n",
    "                net += float(data[0]) * self.w1[i]\n",
    "                net += float(data[1]) * self.w1[i + self.num_layer_hid]\n",
    "                net += self.w1[i + self.num_layer_in * self.num_layer_hid]\n",
    "                net_hid.append(net)\n",
    "                out_hid.append(f(net))\n",
    "\n",
    "            # Calculate net input and output for output layer\n",
    "            net = 0\n",
    "            for i in range(self.num_layer_hid):\n",
    "                net += out_hid[i] * self.w2[i]\n",
    "            net += self.w2[self.num_layer_hid * self.num_layer_out]\n",
    "            net_out = net\n",
    "            out_out = f(net)\n",
    "\n",
    "            # w2 weights update\n",
    "            for i in range(len(self.w2)):\n",
    "                if i < len(self.w2) - self.num_layer_out:\n",
    "                    update = self.learning_rate * (float(data[2]) - out_out) * df(net_out) * out_hid[i]\n",
    "                else:\n",
    "                    update = self.learning_rate * (float(data[2]) - out_out) * df(net_out)\n",
    "                updates_w2.append(update)\n",
    "\n",
    "            # w1 weights update\n",
    "            for i in range(len(self.w1)):\n",
    "                if i < len(self.w1) - self.num_layer_hid:\n",
    "                    if i < 4:\n",
    "                        update = self.learning_rate * (float(data[2]) - out_out) * df(net_out) * self.w2[i % 4] * df(net_hid[i % 4]) * float(data[0])\n",
    "                    else:\n",
    "                        update = self.learning_rate * (float(data[2]) - out_out) * df(net_out) * self.w2[i % 4] * df(net_hid[i % 4]) * float(data[1])\n",
    "                else:\n",
    "                    update = self.learning_rate * (float(data[2]) - out_out) * df(net_out) * self.w2[i % 4] * df(net_hid[i % 4])\n",
    "                updates_w1.append(update)\n",
    "\n",
    "            # update weights w1\n",
    "            for i, update in enumerate(updates_w1):\n",
    "                self.w1[i] += update\n",
    "\n",
    "            # update weights w2\n",
    "            for i, update in enumerate(updates_w2):\n",
    "                self.w2[i] += update\n",
    "\n",
    "\n",
    "def main():\n",
    "    network = Network(2, 5, 1)\n",
    "    train_data = []\n",
    "    f = open('./input_dataset.in')\n",
    "\n",
    "    try:\n",
    "\n",
    "        while 1: \n",
    "            new_in = f.readline().split(',')\n",
    "            if len(new_in) < 3:\n",
    "                break\n",
    "            train_data.append(new_in)\n",
    "            \n",
    "\n",
    "        for _ in range(100):\n",
    "            network.train(train_data)\n",
    "\n",
    "        f = open('./testing_dataset.in')\n",
    "        out_data = []\n",
    "        test_data = []\n",
    "        out_data_prob = []\n",
    "        while 1:\n",
    "            new_in = f.readline().split(',')\n",
    "            if len(new_in) < 2:\n",
    "                break\n",
    "            new_in[0] = new_in[0][new_in[0].rfind(' ') + 1:]\n",
    "            new_in[1] = new_in[1][new_in[1].rfind(' ') + 1:]\n",
    "            output = network.forward_propagation(new_in)\n",
    "            test_data.append(new_in)\n",
    "            out_data_prob.append(output)\n",
    "            if output > 0:\n",
    "                output = '+1'\n",
    "            else:\n",
    "                output = '-1'\n",
    "            out_data.append(output)\n",
    "                \n",
    "        f = open('./expected_dataset.in')\n",
    "        out_expect_data = []\n",
    "        while 1:\n",
    "            new_in = f.readline().split('\\n')\n",
    "            if len(new_in) < 2:\n",
    "                break\n",
    "            out_expect_data.append(new_in[0])    \n",
    "\n",
    "    except EOFError:\n",
    "        print('', end='')\n",
    "        \n",
    "    plt.figure(3)\n",
    "    plt.plot(out_data, 'bo') \n",
    "    plt.plot(out_expect_data,'r+')\n",
    "    plt.title('Klassenlabels')\n",
    "    plt.box(\"off\")\n",
    "    plt.savefig('output-klass.png')\n",
    "    plt.show()\n",
    "\n",
    "    # AUC / ROC curves \n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from matplotlib import pyplot\n",
    "    lr_auc = roc_auc_score(list(map(int, out_expect_data)), out_data_prob)\n",
    "    # summarize scores\n",
    "    print('NN AUC=%.3f' % (lr_auc))\n",
    "    # calculate roc curves\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(list(map(int, out_expect_data)), out_data_prob)\n",
    "    # plot the roc curve for the model\n",
    "    pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ANN')\n",
    "    # axis labels\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig('output-roc.png')\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
